{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Armando5347/polaridad-opinion/blob/main/polaridad_de_opinion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpwxKfk-2U7n"
   },
   "source": [
    "**Imports a utilizar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "QJPUFQv_fqxr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizar el texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    reemplazos = {\n",
    "        'á': 'a', 'é': 'e', 'í': 'i', 'ó': 'o', 'ú': 'u',\n",
    "        'à': 'a', 'è': 'e', 'ì': 'i', 'ò': 'o', 'ù': 'u',\n",
    "        'ä': 'a', 'ë': 'e', 'ï': 'i', 'ö': 'o', 'ü': 'u',\n",
    "        'ñ': 'n'\n",
    "    }\n",
    "    \n",
    "    for acentuada, normal in reemplazos.items():\n",
    "        texto = texto.replace(acentuada, normal)\n",
    "    \n",
    "    return texto\n",
    "\n",
    "config = {\n",
    "    'processors': 'tokenize,mwt,pos,lemma',\n",
    "    'lang': 'es'\n",
    "}\n",
    "\n",
    "nlp = stanza.Pipeline(**config)\n",
    "\n",
    "def normalizarTexto(texto, limpia, quita_stopwords, lematiza):\n",
    "    if limpia:\n",
    "        texto = limpiar_texto(texto)\n",
    "\n",
    "    try:\n",
    "        doc = nlp(texto)\n",
    "        cadenaNorm = \"\"\n",
    "        for sent in doc.sentences:\n",
    "            for token in sent.words:\n",
    "                if quita_stopwords and lematiza:\n",
    "                    if token.pos not in {'ADP', 'CCONJ', 'DET', 'SCONJ', 'PRON'}:\n",
    "                        cadenaNorm += token.lemma + \" \"\n",
    "                elif quita_stopwords:\n",
    "                    if token.pos not in {'ADP', 'CCONJ', 'DET', 'SCONJ', 'PRON'}:\n",
    "                        cadenaNorm += token.text + \" \"\n",
    "                elif lematiza:\n",
    "                    cadenaNorm += token.lemma + \" \"\n",
    "                else:\n",
    "                    cadenaNorm += token.text + \" \"\n",
    "    except:\n",
    "        cadenaNorm = \"\"\n",
    "\n",
    "    return cadenaNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx1a3JqU2k4v"
   },
   "source": [
    "**Obtener el dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Dd51DDjO2n2x",
    "outputId": "3378958e-2506-4c3e-b06a-2e03838d36fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Piensen dos veces antes de ir a este hotel, te...\n",
      "1        Cuatro de nosotros fuimos recientemente a Eddi...\n",
      "2        seguiré corta y simple: limpieza\\n- bad. Tengo...\n",
      "3        Al reservar un hotel con multipropiedad Mayan ...\n",
      "4        No pierdan su tiempo ni dinero, venimos porque...\n",
      "                               ...                        \n",
      "30207    Es una construcción majestuosa, creo que de la...\n",
      "30208    Muy al estilo de Romeo y Julieta es este sitio...\n",
      "30209    Ideal para subir las escalinatas y divisar su ...\n",
      "30210    Es imperdible, de ahí puedes ver muy bien la c...\n",
      "30211    No te puedes ir de Guanajuato sin visitarlo......\n",
      "Name: Opinion, Length: 30212, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_excel(\"Rest_Mex_2022.xlsx\")\n",
    "print (data['Opinion'])\n",
    "\n",
    "train_split, test_split = train_test_split(\n",
    "        data,\n",
    "        test_size=0.2,  # 20% para prueba y 80% para entrenamiento\n",
    "        random_state=0,  # Semilla para asegurar reproducibilidad\n",
    "        stratify=data['Polarity']  # Mantener proporciones de clase\n",
    "    )\n",
    "\n",
    "X_train = train_split[\"Opinion\"]\n",
    "y_train = train_split[\"Polarity\"]\n",
    "X_test = test_split[\"Opinion\"]\n",
    "y_test = test_split[\"Polarity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_KRhWCs-GY1"
   },
   "source": [
    "**Crear pipeline, junto con los grid_search_view para los clasificadores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "id": "H2gA3Lbv-OPT",
    "outputId": "c02e0d7c-4ca1-40d5-f336-880c0190c167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la maquina de soporte vectorial\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n    X = super().fit_transform(raw_documents)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1372, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1259, in _count_vocab\n    for feature in analyze(doc):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 103, in _analyze\n    doc = decoder(doc)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 236, in decode\n    raise ValueError(\nValueError: np.nan is an invalid document, expected byte or unicode string.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-40ff2f0d61e3>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resultados del perceptrón multicapa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# Entrenar el modelo con GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     )\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             )\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 2091, in fit_transform\n    X = super().fit_transform(raw_documents)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1372, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 1259, in _count_vocab\n    for feature in analyze(doc):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 103, in _analyze\n    doc = decoder(doc)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\", line 236, in decode\n    raise ValueError(\nValueError: np.nan is an invalid document, expected byte or unicode string.\n"
     ]
    }
   ],
   "source": [
    "clasificadores = [SVC(random_state=0), MLPClassifier(max_iter=1000, random_state=0)]\n",
    "param_grid_svc = {\n",
    "                'classifier__C': [0.1, 1, 10],  # Hiperparámetro C para SVM\n",
    "                'classifier__kernel': ['linear', 'rbf', 'poly'],  # Tipo de kernel\n",
    "                'classifier__gamma': ['scale', 'auto']  # Parámetro gamma\n",
    "            }\n",
    "\n",
    "param_grid_mlp = {\n",
    "                'classifier__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "                'classifier__activation': ['tanh', 'relu'], #funcion de activacion\n",
    "                'classifier__alpha': [0.0001, 0.001, 0.01]\n",
    "            }\n",
    "for clasificador in clasificadores:\n",
    "  pipe = Pipeline([('text_representation', TfidfVectorizer(token_pattern= r'(?u)\\w+|\\w+\\n|\\.|\\¿|\\?', ngram_range=(1,1))),\n",
    "                   ('scaler', StandardScaler()), ('classifier',clasificador)])\n",
    "  #aqui, cv hace cross validation por su cuenta, y busca ajustar los mejores hipermarametros a partir del f1-macro\n",
    "  if isinstance(clasificador, SVC):\n",
    "    grid_search = GridSearchCV(pipe, param_grid_svc, cv=5,scoring='accuracy')\n",
    "    print(\"Resultados de la maquina de soporte vectorial\")\n",
    "  else:\n",
    "    grid_search = GridSearchCV(pipe, param_grid_mlp, cv=5, scoring='accuracy')\n",
    "    print(\"Resultados del perceptrón multicapa\")\n",
    "  # Entrenar el modelo con GridSearchCV\n",
    "  grid_search.fit(X_train, y_train)\n",
    "  print(str(grid_search.best_params_))\n",
    "  y_pred = grid_search.predict(X_test)\n",
    "  print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxSK5BCTlOkkpczkf5cArD",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
